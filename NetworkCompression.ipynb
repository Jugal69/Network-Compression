{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW3Q1.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "T5xm3KmdoldR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Problem 1: Network Compression Using SVD**\n",
        "\n",
        "Loading all the libraries"
      ]
    },
    {
      "metadata": {
        "id": "F9Nnbg3rrpwn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.framework import ops\n",
        "import numpy as np\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fnaxE46mo3-X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Loading the MNIST dataset"
      ]
    },
    {
      "metadata": {
        "id": "_Y5UJ_eFtOIG",
        "colab_type": "code",
        "outputId": "e6c55ff2-73e9-4cd4-b49b-e72a798dbf90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        }
      },
      "cell_type": "code",
      "source": [
        "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
        "trainX, trainY, testX, testY = mnist.train.images, mnist.train.labels, mnist.test.images, mnist.test.labels\n",
        "print(trainY.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-2-803ab4856a87>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "(55000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "38DZ0rTMo9Eu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Define the architecture of the neural network\n",
        "\n",
        "Learning rate=0.0008"
      ]
    },
    {
      "metadata": {
        "id": "SLC0XLeYuDJi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()  # To reset all the parameters of the graph for every execution\n",
        "tf.random.set_random_seed(0)\n",
        "input_units=784   # Total number of input units\n",
        "lr=tf.constant(.0008, dtype=tf.float32, name='learningRate')\n",
        "hidden_units=1024   # Total number of hidden units\n",
        "output_units=10    # Total number of output units\n",
        "x=tf.placeholder(tf.float32,shape=[None,input_units])\n",
        "y=tf.placeholder(tf.float32,shape=[None,output_units])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LDnV4OzOpN_4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Randomly initialize the weights & biases for all the layers using He Initialization"
      ]
    },
    {
      "metadata": {
        "id": "k4uIcCVxuQdD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "f1c1cc44-12bb-4ed4-92da-64d68d39ef37"
      },
      "cell_type": "code",
      "source": [
        "w1 = tf.get_variable(\"W1\", shape=[input_units, hidden_units], initializer=tf.initializers.he_normal())\n",
        "b1 = tf.get_variable(\"b1\", shape=[1,hidden_units], initializer=tf.initializers.he_normal())\n",
        "w2 = tf.get_variable(\"W2\", shape=[hidden_units, hidden_units], initializer=tf.initializers.he_normal())\n",
        "b2 = tf.get_variable(\"b2\", shape=[1,hidden_units], initializer=tf.initializers.he_normal())\n",
        "w3 = tf.get_variable(\"W3\", shape=[hidden_units, hidden_units], initializer=tf.initializers.he_normal())\n",
        "b3 = tf.get_variable(\"b3\", shape=[1,hidden_units], initializer=tf.initializers.he_normal())\n",
        "w4 = tf.get_variable(\"W4\", shape=[hidden_units, hidden_units], initializer=tf.initializers.he_normal())\n",
        "b4 = tf.get_variable(\"b4\", shape=[1,hidden_units], initializer=tf.initializers.he_normal())\n",
        "w5 = tf.get_variable(\"W5\", shape=[hidden_units, hidden_units], initializer=tf.initializers.he_normal())\n",
        "b5 = tf.get_variable(\"b5\", shape=[1,hidden_units], initializer=tf.initializers.he_normal())\n",
        "w6 = tf.get_variable(\"W6\", shape=[hidden_units, output_units], initializer=tf.initializers.he_normal())\n",
        "b6 = tf.get_variable(\"b6\", shape=[1,output_units], initializer=tf.initializers.he_normal())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YO_B4WqXpSLI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Feedforward network"
      ]
    },
    {
      "metadata": {
        "id": "--i2QBBGuRYF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "a1=tf.nn.relu(x@w1+b1)  # 1st hidden layer\n",
        "a2=tf.nn.relu(a1@w2+b2)  # 2nd hidden layer\n",
        "a3=tf.nn.relu(a2@w3+b3)  # 3rd hidden layer\n",
        "a4=tf.nn.relu(a3@w4+b4)  # 4th hidden layer\n",
        "a5=tf.nn.relu(a4@w5+b5)  # 5th hidden layer\n",
        "yhat=tf.nn.softmax(a5@w6+b6)  # output layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FW7ulQUNpX9O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Training the DNN:-\n",
        "\n",
        "Loss function : Cross-entropy\n",
        "\n",
        "Optimizer : Adam Optimizer"
      ]
    },
    {
      "metadata": {
        "id": "oDMmn-IHuktG",
        "colab_type": "code",
        "outputId": "d69ec6f8-977a-4e1c-9726-a67650efaecc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "loss=tf.reduce_sum(-y*tf.log(yhat))  # Cross-entropy\n",
        "train_step = tf.train.AdamOptimizer(learning_rate=lr).minimize(loss)  # Adam Optimization\n",
        "sess=tf.InteractiveSession()\n",
        "tf.global_variables_initializer().run()\n",
        "maxEpoch=251  # Total number of epochs\n",
        "for i in range(maxEpoch):\n",
        "  errt, _=sess.run([loss,train_step], feed_dict={x:trainX, y: trainY})\n",
        "  if not i%25:\n",
        "    print('Epoch number:',i,' Loss:',errt)\n",
        "print(' Accuracy:',sess.run(tf.reduce_mean(tf.cast(tf.equal(tf.argmax(yhat,axis=1),tf.argmax(y,axis=1)), tf.float32)), feed_dict={x: testX, y: testY})*100,'%')\n",
        "w1_baseline,w2_baseline,w3_baseline,w4_baseline,w5_baseline,w6_baseline=sess.run([w1,w2,w3,w4,w5,w6],feed_dict={x:trainX})\n",
        "b1_baseline,b2_baseline,b3_baseline,b4_baseline,b5_baseline,b6_baseline=sess.run([b1,b2,b3,b4,b5,b6],feed_dict={x:trainX})"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch number: 0  Loss: 253220.66\n",
            "Epoch number: 25  Loss: 72198.85\n",
            "Epoch number: 50  Loss: 16597.188\n",
            "Epoch number: 75  Loss: 8938.847\n",
            "Epoch number: 100  Loss: 5044.214\n",
            "Epoch number: 125  Loss: 2881.9004\n",
            "Epoch number: 150  Loss: 7846.703\n",
            "Epoch number: 175  Loss: 3438.2666\n",
            "Epoch number: 200  Loss: 1948.709\n",
            "Epoch number: 225  Loss: 1004.2184\n",
            "Epoch number: 250  Loss: 450.9746\n",
            " Accuracy: 97.69999980926514 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XL7BKGoiqQ0C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "SVD on all the weight matrices"
      ]
    },
    {
      "metadata": {
        "id": "GRajyCe1XF46",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "u1, s1, v1 = np.linalg.svd(w1_baseline,full_matrices=False)\n",
        "u2, s2, v2 = np.linalg.svd(w2_baseline,full_matrices=False)\n",
        "u3, s3, v3 = np.linalg.svd(w3_baseline,full_matrices=False)\n",
        "u4, s4, v4 = np.linalg.svd(w4_baseline,full_matrices=False)\n",
        "u5, s5, v5 = np.linalg.svd(w5_baseline,full_matrices=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mUje1XIpqYMs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Function to perform feed forward using the SVD approximated weights"
      ]
    },
    {
      "metadata": {
        "id": "Pv8O2pqoYny_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def getOutput(w11,w12,w21,w22,w31,w32,w41,w42,w51,w52,X):\n",
        "  a1=np.maximum(np.dot(np.dot(X,w11),w12)+b1_baseline,0)  # 1st Hidden layer\n",
        "  a2=np.maximum(np.dot(np.dot(a1,w21),w22)+b2_baseline,0)  # 2nd Hidden layer\n",
        "  a3=np.maximum(np.dot(np.dot(a2,w31),w32)+b3_baseline,0)  # 3rd Hidden layer\n",
        "  a4=np.maximum(np.dot(np.dot(a3,w41),w42)+b4_baseline,0)  # 4th Hidden layer\n",
        "  a5=np.maximum(np.dot(np.dot(a4,w51),w52)+b5_baseline,0)  # 5th Hidden layer\n",
        "  a6=np.exp(np.dot(a5,w6_baseline)+b6_baseline)\n",
        "  return np.argmax(a6/np.sum(a6,axis=1).reshape((-1,1)),axis=1)  # Output layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lqMSh0Hoqmww",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Calculate the accuracy of all the DNNs with weights approximated using SVD with dimension D=10,20,50,100,200"
      ]
    },
    {
      "metadata": {
        "id": "lGphKr3peprX",
        "colab_type": "code",
        "outputId": "6456eedb-1db9-487a-9b45-856aec0bfbaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "D=[10,20,50,100,200]\n",
        "accuracy=[]\n",
        "for d in D:\n",
        "  label=getOutput(u1[:,:d]*s1[:d],v1[:d],u2[:,:d]*s2[:d],v2[:d],u3[:,:d]*s3[:d],v3[:d],u4[:,:d]*s4[:d],v4[:d],u5[:,:d]*s5[:d],v5[:d],testX)\n",
        "  accuracy.append(np.sum(label==np.argmax(testY,axis=1))*100/testY.shape[0])\n",
        "  print('D:',d,' Accuracy:',accuracy[-1])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "D: 10  Accuracy: 30.01\n",
            "D: 20  Accuracy: 51.19\n",
            "D: 50  Accuracy: 68.95\n",
            "D: 100  Accuracy: 81.55\n",
            "D: 200  Accuracy: 93.38\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TzjlBi7bryIj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Calculate the accuracy of the DNN with weight approximated using SVD with full dimension"
      ]
    },
    {
      "metadata": {
        "id": "gFwUcVAf6VCr",
        "colab_type": "code",
        "outputId": "86e43954-955e-4dcc-a763-7a8093b366ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "label=getOutput(u1*s1,v1,u2*s2,v2,u3*s3,v3,u4*s4,v4,u5*s5,v5,testX)\n",
        "accuracy.append(np.sum(label==np.argmax(testY,axis=1))*100/testY.shape[0])\n",
        "D.append(784)\n",
        "print('Dfull Accuracy:',accuracy[-1])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dfull Accuracy: 97.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Qxxv0dQTsWM_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Plotting the graph of the accuracy of the DNN for different values of D"
      ]
    },
    {
      "metadata": {
        "id": "D4ZvxgNR65E-",
        "colab_type": "code",
        "outputId": "5ea19804-0a67-47ea-dbf0-bbb68aa741de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        }
      },
      "cell_type": "code",
      "source": [
        "plt.plot(D,accuracy,'bo-')\n",
        "plt.xlabel('Values of D')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n",
        "sess.close()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAAFYCAYAAACoFn5YAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nERNTkIuIiJjY/wejNHuynfllhQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "-6Ly1Efqs3H7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Approach 1)** : Create a new DNN with SVD approximated weights\n",
        "\n",
        "Initializating the weights of the DNN with the SVD approximated value of D=20"
      ]
    },
    {
      "metadata": {
        "id": "NfKqGsJKwuGC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()  # To reset all the parameters of the graph for every execution\n",
        "sess=tf.InteractiveSession()\n",
        "d=20\n",
        "U1 = tf.Variable(u1[:,:d]*s1[:d], name='U1')  # 1st Hidden layer\n",
        "V1 = tf.Variable(v1[:d], name='V1')\n",
        "B1 = tf.Variable(b1_baseline, name='B1')\n",
        "\n",
        "U2 = tf.Variable(u2[:,:d]*s2[:d], name='U2')  # 2nd Hidden layer\n",
        "V2 = tf.Variable(v2[:d], name='V2')\n",
        "B2 = tf.Variable(b2_baseline, name='B2')\n",
        "\n",
        "U3 = tf.Variable(u3[:,:d]*s3[:d], name='U3')  # 3rd Hidden layer\n",
        "V3 = tf.Variable(v3[:d], name='V3')\n",
        "B3 = tf.Variable(b3_baseline, name='B3')\n",
        "\n",
        "U4 = tf.Variable(u4[:,:d]*s4[:d], name='U4')  # 4th Hidden layer\n",
        "V4 = tf.Variable(v4[:d], name='V4')\n",
        "B4 = tf.Variable(b4_baseline, name='B4')\n",
        "\n",
        "U5 = tf.Variable(u5[:,:d]*s5[:d], name='U5')  # 5th Hidden layer\n",
        "V5 = tf.Variable(v5[:d], name='V5')\n",
        "B5 = tf.Variable(b5_baseline, name='B5')\n",
        "\n",
        "W6 = tf.Variable(w6_baseline, name='W6')  # Output layer\n",
        "B6 = tf.Variable(b6_baseline, name='B6')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7gU7P1SVtWRl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Defining the placeholders of the DNN"
      ]
    },
    {
      "metadata": {
        "id": "J874h6GnjHi9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lr=0.0005  # Learning rate\n",
        "x=tf.placeholder(tf.float32,shape=[None,input_units])\n",
        "y=tf.placeholder(tf.float32,shape=[None,output_units])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b1e7_4Idjwq-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess.run(tf.variables_initializer(var_list=[V1, U1, V2, U2, V3, U3, V4, U4, V5, U5, B1, B2, B3, B4, B5, W6, B6]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-1FC48e3thVj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Architecture of the new DNN"
      ]
    },
    {
      "metadata": {
        "id": "6m02r_xOkMW7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "a1=tf.nn.relu(x@U1@V1+B1)  # 1st hidden layer\n",
        "a2=tf.nn.relu(a1@U2@V2+B2)  # 2nd hidden layer\n",
        "a3=tf.nn.relu(a2@U3@V3+B3)  # 3rd hidden layer\n",
        "a4=tf.nn.relu(a3@U4@V4+B4)  # 4th hidden layer\n",
        "a5=tf.nn.relu(a4@U5@V5+B5)  # 5th hidden layer\n",
        "yhat=tf.nn.softmax(a5@W6+B6)  # output layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7MkAbuqRtkyu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Training the new DNN:\n",
        "\n",
        "Learning rate=0.0005\n",
        "\n",
        "Loss function=Cross-entropy\n",
        "\n",
        "Optimizer=Adam Optimizer"
      ]
    },
    {
      "metadata": {
        "id": "K2_s9GhHlZ9Z",
        "colab_type": "code",
        "outputId": "37ee917d-f205-4c04-bab1-10ed2d802a72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "cell_type": "code",
      "source": [
        "temp = set(tf.global_variables())\n",
        "loss=tf.reduce_sum(-y*tf.log(yhat))  # Cross-entropy\n",
        "train_step = tf.train.AdamOptimizer(learning_rate=lr).minimize(loss)  # Adam Optimization\n",
        "tf.variables_initializer(set(tf.global_variables())-temp).run()\n",
        "maxEpoch=306  # Total number of epochs\n",
        "for i in range(maxEpoch):\n",
        "  errt, _=sess.run([loss,train_step], feed_dict={x:trainX, y: trainY})\n",
        "  if not i%50:\n",
        "    print('Epoch number:',i,' Loss:',errt)\n",
        "print('Accuracy:',sess.run(tf.reduce_mean(tf.cast(tf.equal(tf.argmax(yhat,axis=1),tf.argmax(y,axis=1)), tf.float32)), feed_dict={x: testX, y: testY})*100,'%')\n",
        "sess.close()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch number: 0  Loss: 78981.66\n",
            "Epoch number: 50  Loss: 9273.109\n",
            "Epoch number: 100  Loss: 6527.9746\n",
            "Epoch number: 150  Loss: 5067.6733\n",
            "Epoch number: 200  Loss: 3999.0254\n",
            "Epoch number: 250  Loss: 3208.815\n",
            "Epoch number: 300  Loss: 2648.535\n",
            "Accuracy: 97.00000286102295 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fjDvGLwyupVV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Approach 2)** : Performing SVD at every iteration"
      ]
    },
    {
      "metadata": {
        "id": "V69ZbPcuxndf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def svd_approx(w, name=None):  \n",
        "    with tf.name_scope(name, \"SVDApprox\", [w]) as name:\n",
        "        return py_func(forward_func,[w],[np.float32],grad=backprop_func,name=name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MBIJ03FiPWv_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def py_func(func, inp, Tout, grad, stateful=True, name=None):\n",
        "    rnd_name = 'PyFuncGrad'+ str(np.random.randint(0, 1E+8))  # Random name for the Gradient function of each weight\n",
        "    tf.RegisterGradient(rnd_name)(grad)\n",
        "    g=tf.get_default_graph()\n",
        "    with g.gradient_override_map({\"PyFunc\": rnd_name}):   \n",
        "        return tf.py_func(func, inp, Tout, stateful=stateful, name=name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F71ip0muIgfR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def forward_func(w):  # Function that computes SVD of the weight matrix & reconstructs the weight matrix using just the first 20 components\n",
        "  u, s, v = np.linalg.svd(w,full_matrices=False)\n",
        "  return np.dot(u[:,:d]*s[:d],v[:d])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ERNeOX46JnEi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def backprop_func(op,grad):  # Function to define the custom gradient of the loss function w.r.t each weight\n",
        "  return grad * op.inputs[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z4UDP6IZpu1c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()  # To reset all the parameters of the graph for every execution\n",
        "w1 = tf.Variable(w1_baseline, name='w1')\n",
        "b1 = tf.Variable(b1_baseline, name='b1')\n",
        "\n",
        "w2 = tf.Variable(w2_baseline, name='w2')\n",
        "b2 = tf.Variable(b2_baseline, name='b2')\n",
        "\n",
        "w3 = tf.Variable(w3_baseline, name='w3')\n",
        "b3 = tf.Variable(b3_baseline, name='b3')\n",
        "\n",
        "w4 = tf.Variable(w4_baseline, name='w4')\n",
        "b4 = tf.Variable(b4_baseline, name='b4')\n",
        "\n",
        "w5 = tf.Variable(w5_baseline, name='w5')\n",
        "b5 = tf.Variable(b5_baseline, name='b5')\n",
        "\n",
        "w6 = tf.Variable(w6_baseline, name='w6')\n",
        "b6 = tf.Variable(b6_baseline, name='b6')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3T_QWaN6ry3-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lr=0.00004  # Learning rate\n",
        "x=tf.placeholder(tf.float32,shape=[None,input_units])\n",
        "y=tf.placeholder(tf.float32,shape=[None,output_units])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nOHSECVvr0DB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess=tf.InteractiveSession()\n",
        "sess.run(tf.variables_initializer(var_list=[w1, w2, w3, w4, w5, b1, b2, b3, b4, b5, w6, b6]))  # Initialize all the weights & biases of the network"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "twvDsvaZ5OFw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Architecture of the neural network"
      ]
    },
    {
      "metadata": {
        "id": "2LVSdSomr0bd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "4497bbcb-bcbe-4ead-9298-d8959603aa28"
      },
      "cell_type": "code",
      "source": [
        "a1=tf.nn.relu(x@svd_approx(w1)[0]+b1)  # 1st hidden layer\n",
        "a2=tf.nn.relu(a1@svd_approx(w2)[0]+b2)  # 2nd hidden layer\n",
        "a3=tf.nn.relu(a2@svd_approx(w3)[0]+b3)  # 3rd hidden layer\n",
        "a4=tf.nn.relu(a3@svd_approx(w4)[0]+b4)  # 4th hidden layer\n",
        "a5=tf.nn.relu(a4@svd_approx(w5)[0]+b5)  # 5th hidden layer\n",
        "yhat=tf.nn.softmax(a5@w6+b6)  # output layer"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-18-2248f505c45d>:6: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, use\n",
            "    tf.py_function, which takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dHyoP20qxKxM",
        "colab_type": "code",
        "outputId": "f91fdb21-3f36-4fd6-8549-0e2680bc2741",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "cell_type": "code",
      "source": [
        "temp = set(tf.global_variables())\n",
        "loss=tf.reduce_sum(-y*tf.log(yhat))  # Cross-entropy\n",
        "train_step = tf.train.AdamOptimizer(learning_rate=lr).minimize(loss)   # Adam Optimization\n",
        "tf.variables_initializer(set(tf.global_variables())-temp).run()\n",
        "maxEpoch=1001  # Total number of epochs\n",
        "for i in range(maxEpoch):\n",
        "  errt,_=sess.run([loss,train_step], feed_dict={x:trainX, y: trainY})\n",
        "  if not i%50:\n",
        "    print('Epoch number:',i,' Loss:',errt)\n",
        "print('Accuracy:',sess.run(tf.reduce_mean(tf.cast(tf.equal(tf.argmax(yhat,axis=1),tf.argmax(y,axis=1)), tf.float32)), feed_dict={x: testX, y: testY})*100,'%')\n",
        "sess.close()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch number: 0  Loss: 78981.66\n",
            "Epoch number: 50  Loss: 36530.004\n",
            "Epoch number: 100  Loss: 29784.207\n",
            "Epoch number: 150  Loss: 26823.656\n",
            "Epoch number: 200  Loss: 24652.156\n",
            "Epoch number: 250  Loss: 22742.342\n",
            "Epoch number: 300  Loss: 21121.076\n",
            "Epoch number: 350  Loss: 19796.074\n",
            "Epoch number: 400  Loss: 18713.27\n",
            "Epoch number: 450  Loss: 17866.656\n",
            "Epoch number: 500  Loss: 17344.678\n",
            "Epoch number: 550  Loss: 16929.03\n",
            "Epoch number: 600  Loss: 16457.252\n",
            "Epoch number: 650  Loss: 16035.494\n",
            "Epoch number: 700  Loss: 15597.636\n",
            "Epoch number: 750  Loss: 15400.366\n",
            "Epoch number: 800  Loss: 15204.808\n",
            "Epoch number: 850  Loss: 15062.45\n",
            "Epoch number: 900  Loss: 14885.204\n",
            "Epoch number: 950  Loss: 14675.687\n",
            "Epoch number: 1000  Loss: 14638.802\n",
            "Accuracy: 91.97999835014343 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}